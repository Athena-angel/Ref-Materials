WEBVTT

1
00:00:00.330 --> 00:00:00.996
>> Welcome back.

2
00:00:00.996 --> 00:00:04.907
There's a lot of exciting material
to go over this week, and

3
00:00:04.907 --> 00:00:09.661
one of the first topics that Mike will
share with you in a little bit is a deep

4
00:00:09.661 --> 00:00:13.252
dive into how transformer
networks actually work.

5
00:00:13.252 --> 00:00:16.532
>> Yeah, so look,
it's a complicated topic, right?

6
00:00:16.532 --> 00:00:20.030
In 2017, the paper came out,
Attention is all You Need, and

7
00:00:20.030 --> 00:00:24.254
it laid out all of these fairly complex
data processes which are going to happen

8
00:00:24.254 --> 00:00:26.594
inside the transformer architecture.

9
00:00:26.594 --> 00:00:31.298
So we take a little bit of a high level
view, but we do go down into some depths.

10
00:00:31.298 --> 00:00:33.682
We talk about things
like self-attention and

11
00:00:33.682 --> 00:00:36.354
the multi-headed self-attention mechanism.

12
00:00:36.354 --> 00:00:40.316
So we can see why it is that
these models actually work,

13
00:00:40.316 --> 00:00:45.126
how it is that they actually gain
an understanding of language.

14
00:00:45.126 --> 00:00:48.870
>> And it's amazing how long the
transformer architecture has been around

15
00:00:48.870 --> 00:00:51.494
and it's still state of the art for
many models.

16
00:00:51.494 --> 00:00:56.289
>> I remember after I saw the transformer
paper when it first came out, I thought,

17
00:00:56.289 --> 00:00:58.058
yep, I get this equation.

18
00:00:58.058 --> 00:01:00.538
I acknowledge this is a math equation.

19
00:01:00.538 --> 00:01:02.500
But what's it actually doing?

20
00:01:02.500 --> 00:01:04.154
And it's always seemed
a little bit magical.

21
00:01:04.154 --> 00:01:08.056
It took me a long time playing with it to
finally go, okay, this is why it works.

22
00:01:08.056 --> 00:01:12.106
And so I think in this first week,
you learn the intuitions behind

23
00:01:12.106 --> 00:01:17.102
some of these terms you may have heard
before, like multi-headed attention.

24
00:01:17.102 --> 00:01:19.116
What is that and why does it make sense?

25
00:01:19.116 --> 00:01:23.276
And why did the transformer
architecture really take off?

26
00:01:23.276 --> 00:01:27.038
I think attention had been around for
a long time, but actually thought it was,

27
00:01:27.038 --> 00:01:29.788
one of the things that really
made to take off was it allowed

28
00:01:29.788 --> 00:01:32.092
attention to work in
a massively parallel way.

29
00:01:32.092 --> 00:01:35.628
So it made it work on modern GPUs and
could scale it up.

30
00:01:35.628 --> 00:01:40.274
I think these nuances around transformers
are not well-understood by many, so

31
00:01:40.274 --> 00:01:43.188
looking forward to when
you deep dive into that.

32
00:01:43.188 --> 00:01:45.353
>> Absolutely, I mean,
the scale is part of it and

33
00:01:45.353 --> 00:01:47.220
how it's able to take in all that data.

34
00:01:47.220 --> 00:01:50.820
I just want to say as well, though, that
we're not going to go into this at such

35
00:01:50.820 --> 00:01:53.370
a level which is going to
make people's heads explode.

36
00:01:53.370 --> 00:01:56.644
If they want to do that, then they
can go ahead and read that paper too.

37
00:01:56.644 --> 00:02:00.302
What we're going to do is we're going
to look at the really important

38
00:02:00.302 --> 00:02:04.528
parts of that transformer architecture
that gives you the intuition you need so

39
00:02:04.528 --> 00:02:08.490
that you can actually make
practical use out of these models.

40
00:02:08.490 --> 00:02:12.775
>> One thing I've been surprised and
delighted by is how transformers,

41
00:02:12.775 --> 00:02:17.566
even though this course focuses on text,
it's been really interesting to see

42
00:02:17.566 --> 00:02:21.850
how that basic transformer architecture
is creating a foundation for

43
00:02:21.850 --> 00:02:23.792
vision transformers as well.

44
00:02:23.792 --> 00:02:27.986
So even though in this course you learn
mostly about large language models,

45
00:02:27.986 --> 00:02:32.378
models about text, I think understanding
transformers is also helping people

46
00:02:32.378 --> 00:02:37.092
understand this really exciting vision
transformer and other modalities as well.

47
00:02:37.092 --> 00:02:39.313
It's going to be a really
critical building block for

48
00:02:39.313 --> 00:02:40.660
a lot of machine learning.

49
00:02:40.660 --> 00:02:41.396
>> Absolutely.

50
00:02:41.396 --> 00:02:46.688
>> And then beyond transformers, there's
a second major topic that looking forward

51
00:02:46.688 --> 00:02:51.934
to having this first week cover, which
is the Generative AI project Lifecycle.

52
00:02:51.934 --> 00:02:56.216
I know a lot of people are thinking, boy,
does all this LM stuff, what I do of it?

53
00:02:56.216 --> 00:03:01.599
And the Generative AI project Lifecycle,
which will talk about in a little bit,

54
00:03:01.599 --> 00:03:06.810
helps you plan out how to think about
building your own Generative AI project.

55
00:03:06.810 --> 00:03:08.059
>> That's right, and

56
00:03:08.059 --> 00:03:13.056
the Generative AI project Lifecycle walks
you through the individual stages and

57
00:03:13.056 --> 00:03:18.140
decisions you have to make when you're
developing Generative AI applications.

58
00:03:18.140 --> 00:03:22.033
So one of the first things you have
to decide is whether you're taking

59
00:03:22.033 --> 00:03:26.869
a foundation model off the shelf or you're
actually pre-training your own model and

60
00:03:26.869 --> 00:03:29.756
then as a follow up,
whether you want to fine tune and

61
00:03:29.756 --> 00:03:32.852
customize that model maybe for
your specific data.

62
00:03:32.852 --> 00:03:37.045
>> Yeah, in fact, there's so many large
language model options out there,

63
00:03:37.045 --> 00:03:41.567
some open source, some not open source,
that I see many developers wondering,

64
00:03:41.567 --> 00:03:43.752
which of these models do I want to use?

65
00:03:43.752 --> 00:03:48.295
And so having a way to evaluate it and
then also choose the right model sizing.

66
00:03:48.295 --> 00:03:53.313
I know in your other work, you've talked
about when do you need a giant model, 100

67
00:03:53.313 --> 00:03:58.052
billion or even much bigger versus when
can a 1 to 30 billion parameter model or

68
00:03:58.052 --> 00:04:03.152
even sub 1 billion parameter model be just
fantastic for a specific application?

69
00:04:03.152 --> 00:04:07.750
>> Exactly, so there might be use cases
where you really need the model to be very

70
00:04:07.750 --> 00:04:11.862
comprehensive and able to generalize
to a lot of different tasks.

71
00:04:11.862 --> 00:04:14.932
And there might be use cases
where you're just optimizing for

72
00:04:14.932 --> 00:04:16.417
a single-use case, right?

73
00:04:16.417 --> 00:04:20.137
And you can potentially work with
a smaller model and achieving similar or

74
00:04:20.137 --> 00:04:21.466
even very good results.

75
00:04:21.466 --> 00:04:24.683
>> Yeah, I think that might be one
of the really surprising things for

76
00:04:24.683 --> 00:04:28.072
some people to learn is that you can
actually use quite small models and

77
00:04:28.072 --> 00:04:30.488
still get quite a lot of
capability out of them.

78
00:04:30.488 --> 00:04:34.420
>> Yeah, I think when you want your large
language model to have a lot of general

79
00:04:34.420 --> 00:04:38.290
knowledge about the world, when you
wanted to know stuff about history and

80
00:04:38.290 --> 00:04:42.060
philosophy and the sizes and how to
write Python code and so on and so on.

81
00:04:42.060 --> 00:04:46.543
It helps to have a giant model with
hundreds of billions of parameters.

82
00:04:46.543 --> 00:04:49.680
But for
a single task like summarizing dialogue or

83
00:04:49.680 --> 00:04:54.833
acting as a customer service agent for
one company, for applications like that,

84
00:04:54.833 --> 00:04:59.027
sometimes you can use hundreds of
billions of parameters models.

85
00:04:59.027 --> 00:05:01.114
But that's not always necessary.

86
00:05:01.114 --> 00:05:05.508
So lots of really exciting
material to get into this week.

87
00:05:05.508 --> 00:05:10.342
With that, let's go on to the next video
when Mike will kick things off with

88
00:05:10.342 --> 00:05:14.730
a deep dive into many different use
cases of large language models.
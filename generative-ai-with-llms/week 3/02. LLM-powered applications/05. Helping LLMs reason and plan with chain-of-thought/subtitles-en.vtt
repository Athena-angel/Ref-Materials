WEBVTT

1
00:00:00.000 --> 00:00:03.150
As you saw, it is
important that LLMs can

2
00:00:03.150 --> 00:00:06.120
reason through the steps that
an application must take,

3
00:00:06.120 --> 00:00:08.580
to satisfy a user request.

4
00:00:08.580 --> 00:00:10.620
Unfortunately, complex reasoning

5
00:00:10.620 --> 00:00:12.750
can be challenging for LLMs,

6
00:00:12.750 --> 00:00:14.790
especially for
problems that involve

7
00:00:14.790 --> 00:00:17.280
multiple steps or mathematics.

8
00:00:17.280 --> 00:00:20.310
These problems exist
even in large models

9
00:00:20.310 --> 00:00:23.265
that show good performance
at many other tasks.

10
00:00:23.265 --> 00:00:25.620
Here's one example where an LLM

11
00:00:25.620 --> 00:00:27.930
has difficulty
completing the task.

12
00:00:27.930 --> 00:00:29.490
You're asking the model to solve

13
00:00:29.490 --> 00:00:32.070
a simple multi-step
math problem,

14
00:00:32.070 --> 00:00:34.410
to determine how many
apples a cafeteria

15
00:00:34.410 --> 00:00:37.190
has after using
some to make lunch,

16
00:00:37.190 --> 00:00:38.595
and then buying some more.

17
00:00:38.595 --> 00:00:41.480
Your prompt includes a
similar example problem,

18
00:00:41.480 --> 00:00:43.160
complete with the solution,

19
00:00:43.160 --> 00:00:44.630
to help the model understand

20
00:00:44.630 --> 00:00:47.135
the task through
one-shot inference.

21
00:00:47.135 --> 00:00:49.580
If you like, you can
pause the video here

22
00:00:49.580 --> 00:00:52.810
for a moment and solve
the problem yourself.

23
00:00:52.810 --> 00:00:55.355
After processing the prompt,

24
00:00:55.355 --> 00:00:58.130
the model generates the
completion shown here,

25
00:00:58.130 --> 00:01:01.040
stating that the answer is 27.

26
00:01:01.040 --> 00:01:02.855
This answer is incorrect,

27
00:01:02.855 --> 00:01:05.260
as you found out if
you solve the problem.

28
00:01:05.260 --> 00:01:09.275
The cafeteria actually only
has nine apples remaining.

29
00:01:09.275 --> 00:01:12.590
Researchers have been
exploring ways to improve

30
00:01:12.590 --> 00:01:14.615
the performance of
large language models

31
00:01:14.615 --> 00:01:15.740
on reasoning tasks,

32
00:01:15.740 --> 00:01:17.270
like the one you just saw.

33
00:01:17.270 --> 00:01:20.180
One strategy that has
demonstrated some success is

34
00:01:20.180 --> 00:01:23.300
prompting the model to
think more like a human,

35
00:01:23.300 --> 00:01:25.760
by breaking the problem
down into steps.

36
00:01:25.760 --> 00:01:29.030
What do I mean by thinking
more like a human?

37
00:01:29.030 --> 00:01:31.880
Well, here is the
one-shot example problem

38
00:01:31.880 --> 00:01:34.235
from the prompt on
the previous slide.

39
00:01:34.235 --> 00:01:36.650
The task here is to calculate

40
00:01:36.650 --> 00:01:38.570
how many tennis balls Roger

41
00:01:38.570 --> 00:01:40.835
has after buying some new ones.

42
00:01:40.835 --> 00:01:42.800
One way that a
human might tackle

43
00:01:42.800 --> 00:01:44.800
this problem is as follows.

44
00:01:44.800 --> 00:01:47.150
Begin by determining
the number of

45
00:01:47.150 --> 00:01:49.910
tennis balls Roger
has at the start.

46
00:01:49.910 --> 00:01:53.930
Then note that Roger buys
two cans of tennis balls.

47
00:01:53.930 --> 00:01:56.465
Each can contains three balls,

48
00:01:56.465 --> 00:01:59.665
so he has a total of
six new tennis balls.

49
00:01:59.665 --> 00:02:03.795
Next, add these 6 new
balls to the original 5,

50
00:02:03.795 --> 00:02:06.285
for a total of 11 balls.

51
00:02:06.285 --> 00:02:09.565
Then finish by
stating the answer.

52
00:02:09.565 --> 00:02:12.740
These intermediate
calculations form

53
00:02:12.740 --> 00:02:15.560
the reasoning steps that
a human might take,

54
00:02:15.560 --> 00:02:17.960
and the full sequence
of steps illustrates

55
00:02:17.960 --> 00:02:21.320
the chain of thought that went
into solving the problem.

56
00:02:21.320 --> 00:02:23.180
Asking the model to mimic

57
00:02:23.180 --> 00:02:25.880
this behavior is known as
chain of thought prompting.

58
00:02:25.880 --> 00:02:28.520
It works by including
a series of

59
00:02:28.520 --> 00:02:30.485
intermediate
reasoning steps into

60
00:02:30.485 --> 00:02:34.535
any examples that you use for
one or few-shot inference.

61
00:02:34.535 --> 00:02:37.055
By structuring the
examples in this way,

62
00:02:37.055 --> 00:02:38.960
you're essentially
teaching the model how to

63
00:02:38.960 --> 00:02:41.690
reason through the task
to reach a solution.

64
00:02:41.690 --> 00:02:43.730
Here's the same apples problem

65
00:02:43.730 --> 00:02:45.530
you saw a couple of slides ago,

66
00:02:45.530 --> 00:02:48.485
now reworked as a chain
of thought prompt.

67
00:02:48.485 --> 00:02:51.245
The story of Roger
buying the tennis balls

68
00:02:51.245 --> 00:02:54.080
is still used as the
one-shot example.

69
00:02:54.080 --> 00:02:55.715
But this time you include

70
00:02:55.715 --> 00:02:59.455
intermediate reasoning
steps in the solution text.

71
00:02:59.455 --> 00:03:01.460
These steps are basically

72
00:03:01.460 --> 00:03:03.770
equivalent to the ones
a human might take,

73
00:03:03.770 --> 00:03:06.350
that you saw just
a few minutes ago.

74
00:03:06.350 --> 00:03:08.690
You then send this
chain of thought

75
00:03:08.690 --> 00:03:10.955
prompt to the large
language model,

76
00:03:10.955 --> 00:03:13.340
which generates a completion.

77
00:03:13.340 --> 00:03:15.830
Notice that the model
has now produced

78
00:03:15.830 --> 00:03:18.440
a more robust and
transparent response

79
00:03:18.440 --> 00:03:20.630
that explains its
reasoning steps,

80
00:03:20.630 --> 00:03:24.130
following a similar structure
as the one-shot example.

81
00:03:24.130 --> 00:03:25.580
The model now correctly

82
00:03:25.580 --> 00:03:28.145
determines that nine
apples are left.

83
00:03:28.145 --> 00:03:30.320
Thinking through the
problem has helped

84
00:03:30.320 --> 00:03:32.990
the model come to
the correct answer.

85
00:03:32.990 --> 00:03:35.930
One thing to note is that
while the input prompt is

86
00:03:35.930 --> 00:03:38.810
shown here in a condensed
format to save space,

87
00:03:38.810 --> 00:03:42.035
the entire prompt is actually
included in the output.

88
00:03:42.035 --> 00:03:45.350
You can use chain of thought
prompting to help LLMs

89
00:03:45.350 --> 00:03:48.530
improve their reasoning of
other types of problems too,

90
00:03:48.530 --> 00:03:50.755
in addition to arithmetic.

91
00:03:50.755 --> 00:03:54.050
Here's an example of a
simple physics problem,

92
00:03:54.050 --> 00:03:56.390
where the model is being
asked to determine if

93
00:03:56.390 --> 00:03:59.900
a gold ring would sink to the
bottom of a swimming pool.

94
00:03:59.900 --> 00:04:02.390
The chain of thought
prompt included

95
00:04:02.390 --> 00:04:04.370
as the one-shot example here,

96
00:04:04.370 --> 00:04:07.040
shows the model how to
work through this problem,

97
00:04:07.040 --> 00:04:08.975
by reasoning that
a pair would flow

98
00:04:08.975 --> 00:04:11.620
because it's less
dense than water.

99
00:04:11.620 --> 00:04:14.375
When you pass this
prompt to the LLM,

100
00:04:14.375 --> 00:04:17.680
it generates a similarly
structured completion.

101
00:04:17.680 --> 00:04:21.065
The model correctly identifies
the density of gold,

102
00:04:21.065 --> 00:04:23.230
which it learned from
its training data,

103
00:04:23.230 --> 00:04:25.280
and then reasons
that the ring would

104
00:04:25.280 --> 00:04:28.325
sink because gold is much
more dense than water.

105
00:04:28.325 --> 00:04:31.250
Chain of thought prompting
is a powerful technique that

106
00:04:31.250 --> 00:04:32.360
improves the ability of

107
00:04:32.360 --> 00:04:34.805
your model to reason
through problems.

108
00:04:34.805 --> 00:04:36.650
While this can greatly improve

109
00:04:36.650 --> 00:04:38.150
the performance of your model,

110
00:04:38.150 --> 00:04:41.360
the limited math skills
of LLMs can still cause

111
00:04:41.360 --> 00:04:44.915
problems if your task requires
accurate calculations,

112
00:04:44.915 --> 00:04:47.390
like totaling sales on
an e-commerce site,

113
00:04:47.390 --> 00:04:50.795
calculating tax, or
applying a discount.

114
00:04:50.795 --> 00:04:52.850
In the next video,
you'll explore

115
00:04:52.850 --> 00:04:55.610
a technique that can help
you overcome this problem,

116
00:04:55.610 --> 00:04:57.320
by letting your LLM talk to

117
00:04:57.320 --> 00:04:59.705
a program that is
much better at math.

118
00:04:59.705 --> 00:05:02.580
Let's move on and take a look.
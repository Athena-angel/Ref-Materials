WEBVTT

1
00:00:00.000 --> 00:00:02.655
In this final section
of the lesson,

2
00:00:02.655 --> 00:00:05.520
you'll explore some
additional considerations

3
00:00:05.520 --> 00:00:09.030
for building LLM
powered applications.

4
00:00:09.030 --> 00:00:11.205
To begin, let's bring

5
00:00:11.205 --> 00:00:13.500
everything you've seen
so far in the lesson

6
00:00:13.500 --> 00:00:15.900
together and look at
the building blocks for

7
00:00:15.900 --> 00:00:19.230
creating LLM powered
applications.

8
00:00:19.230 --> 00:00:22.170
You'll require several
key components to

9
00:00:22.170 --> 00:00:25.335
create end-to-end solutions
for your applications,

10
00:00:25.335 --> 00:00:28.290
starting with the
infrastructure layer.

11
00:00:28.290 --> 00:00:31.485
This layer provides
the compute, storage,

12
00:00:31.485 --> 00:00:34.065
and network to
serve up your LLMs,

13
00:00:34.065 --> 00:00:37.225
as well as to host your
application components.

14
00:00:37.225 --> 00:00:38.450
You can make use of

15
00:00:38.450 --> 00:00:41.300
your on-premises infrastructure
for this or have it

16
00:00:41.300 --> 00:00:42.605
provided for you via

17
00:00:42.605 --> 00:00:45.695
on-demand and pay-as-you-go
Cloud services.

18
00:00:45.695 --> 00:00:48.470
Next, you'll include the
large language models

19
00:00:48.470 --> 00:00:50.870
you want to use in
your application.

20
00:00:50.870 --> 00:00:53.390
These could include
foundation models,

21
00:00:53.390 --> 00:00:55.040
as well as the models you have

22
00:00:55.040 --> 00:00:57.650
adapted to your specific task.

23
00:00:57.650 --> 00:00:59.510
The models are deployed on

24
00:00:59.510 --> 00:01:02.675
the appropriate infrastructure
for your inference needs.

25
00:01:02.675 --> 00:01:04.670
Taking into account
whether you need

26
00:01:04.670 --> 00:01:08.420
real-time or near-real-time
interaction with the model.

27
00:01:08.420 --> 00:01:10.790
You may also have
the need to retrieve

28
00:01:10.790 --> 00:01:13.145
information from
external sources,

29
00:01:13.145 --> 00:01:14.810
such as those discussed in

30
00:01:14.810 --> 00:01:18.125
the retrieval augmented
generation section.

31
00:01:18.125 --> 00:01:21.500
Your application will
return the completions from

32
00:01:21.500 --> 00:01:22.820
your large language model to

33
00:01:22.820 --> 00:01:25.775
the user or consuming
application.

34
00:01:25.775 --> 00:01:27.635
Depending on your use case,

35
00:01:27.635 --> 00:01:29.750
you may need to
implement a mechanism

36
00:01:29.750 --> 00:01:32.345
to capture and
store the outputs.

37
00:01:32.345 --> 00:01:34.220
For example, you could build

38
00:01:34.220 --> 00:01:36.950
the capacity to store
user completions during

39
00:01:36.950 --> 00:01:38.510
a session to augment

40
00:01:38.510 --> 00:01:42.130
the fixed contexts
window size of your LLM.

41
00:01:42.130 --> 00:01:45.050
You can also gather
feedback from users that

42
00:01:45.050 --> 00:01:47.465
may be useful for
additional fine-tuning,

43
00:01:47.465 --> 00:01:51.785
alignment, or evaluation as
your application matures.

44
00:01:51.785 --> 00:01:53.915
Next, you may need to use

45
00:01:53.915 --> 00:01:55.940
additional tools
and frameworks for

46
00:01:55.940 --> 00:01:58.550
large language models
that help you easily

47
00:01:58.550 --> 00:02:00.200
implement some of the techniques

48
00:02:00.200 --> 00:02:01.795
discussed in this course.

49
00:02:01.795 --> 00:02:03.630
As an example, you can use

50
00:02:03.630 --> 00:02:05.660
len chains built-in libraries to

51
00:02:05.660 --> 00:02:07.790
implement techniques like pow

52
00:02:07.790 --> 00:02:10.865
react or chain of
thought prompting.

53
00:02:10.865 --> 00:02:14.180
You may also utilize model
hubs which allow you to

54
00:02:14.180 --> 00:02:15.830
centrally manage and share

55
00:02:15.830 --> 00:02:18.565
models for use in applications.

56
00:02:18.565 --> 00:02:20.465
In the final layer,

57
00:02:20.465 --> 00:02:22.310
you typically have some type of

58
00:02:22.310 --> 00:02:24.440
user interface that
the application

59
00:02:24.440 --> 00:02:25.715
will be consumed through,

60
00:02:25.715 --> 00:02:28.550
such as a website or a rest API.

61
00:02:28.550 --> 00:02:30.920
This layer is where
you'll also include

62
00:02:30.920 --> 00:02:32.870
the security components required

63
00:02:32.870 --> 00:02:35.675
for interacting with
your application.

64
00:02:35.675 --> 00:02:37.550
At a high level,

65
00:02:37.550 --> 00:02:41.360
this architecture stack
represents the various components

66
00:02:41.360 --> 00:02:45.620
to consider as part of your
generative AI applications.

67
00:02:45.620 --> 00:02:49.280
Your users, whether they
are human end-users or

68
00:02:49.280 --> 00:02:50.840
other systems that access

69
00:02:50.840 --> 00:02:53.390
your application
through its APIs,

70
00:02:53.390 --> 00:02:56.405
will interact with
this entire stack.

71
00:02:56.405 --> 00:03:00.440
As you can see, the model is
typically only one part of

72
00:03:00.440 --> 00:03:01.805
the story in building

73
00:03:01.805 --> 00:03:05.360
end-to-end generative
AI applications.

74
00:03:05.360 --> 00:03:07.940
Congratulations on
making it through

75
00:03:07.940 --> 00:03:10.820
the full generative AI
project life cycle.

76
00:03:10.820 --> 00:03:12.500
Hopefully, you feel like you've

77
00:03:12.500 --> 00:03:14.390
developed some intuition about

78
00:03:14.390 --> 00:03:16.910
the important issues you
have to consider when

79
00:03:16.910 --> 00:03:20.290
building applications
using LLMs.

80
00:03:20.290 --> 00:03:22.790
This week, you saw how to align

81
00:03:22.790 --> 00:03:24.815
your models with
human preferences,

82
00:03:24.815 --> 00:03:27.210
such as helpfulness,
harmlessness,

83
00:03:27.210 --> 00:03:29.990
and honesty by fine-tuning using

84
00:03:29.990 --> 00:03:31.820
a technique called reinforcement

85
00:03:31.820 --> 00:03:33.710
learning with human feedback,

86
00:03:33.710 --> 00:03:36.065
or RLHF for short.

87
00:03:36.065 --> 00:03:39.185
Given the popularity of RLHF,

88
00:03:39.185 --> 00:03:41.900
there are many existing
RL reward models

89
00:03:41.900 --> 00:03:44.555
and human alignment
datasets available,

90
00:03:44.555 --> 00:03:48.265
enabling you to quickly
start aligning your models.

91
00:03:48.265 --> 00:03:50.810
In practice, RLHF is

92
00:03:50.810 --> 00:03:52.820
a very effective
mechanism that you can

93
00:03:52.820 --> 00:03:55.265
use to improve the
alignment of your models,

94
00:03:55.265 --> 00:03:58.205
reduce the toxicity
of their responses,

95
00:03:58.205 --> 00:04:02.420
and let you use your models
more safely in production.

96
00:04:02.420 --> 00:04:05.180
You also saw
important techniques

97
00:04:05.180 --> 00:04:06.590
to optimize your model for

98
00:04:06.590 --> 00:04:08.810
inference by reducing the size

99
00:04:08.810 --> 00:04:10.730
of the model through
distillation,

100
00:04:10.730 --> 00:04:13.235
quantization, or pruning.

101
00:04:13.235 --> 00:04:15.620
This minimizes the amount of

102
00:04:15.620 --> 00:04:17.600
hardware resources needed to

103
00:04:17.600 --> 00:04:20.165
serve your LLMs in production.

104
00:04:20.165 --> 00:04:22.520
Lastly, you explored ways that

105
00:04:22.520 --> 00:04:24.470
you can help your model
perform better in

106
00:04:24.470 --> 00:04:26.510
deployment through
structured prompts and

107
00:04:26.510 --> 00:04:30.335
connections to external data
sources and applications.

108
00:04:30.335 --> 00:04:33.170
LLMs can play an amazing role

109
00:04:33.170 --> 00:04:35.705
as the reasoning engine
in an application,

110
00:04:35.705 --> 00:04:37.490
exploiting their intelligence to

111
00:04:37.490 --> 00:04:40.505
power exciting,
useful applications.

112
00:04:40.505 --> 00:04:42.890
Frameworks like len
chain are making it

113
00:04:42.890 --> 00:04:45.305
possible to quickly
build, deploy,

114
00:04:45.305 --> 00:04:47.980
and test LLM powered
applications,

115
00:04:47.980 --> 00:04:50.795
and it's a very exciting
time for developers.

116
00:04:50.795 --> 00:04:53.000
To wrap up the course on TEA is

117
00:04:53.000 --> 00:04:54.920
going to explore a few areas of

118
00:04:54.920 --> 00:04:57.170
active research that
will likely shape

119
00:04:57.170 --> 00:04:58.730
the trajectory of this field in

120
00:04:58.730 --> 00:05:01.290
the coming months and years.